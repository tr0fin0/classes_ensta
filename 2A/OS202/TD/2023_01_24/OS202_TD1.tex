\documentclass{article}
% \usepackage{C:/Users/guitr/Documents/git_repositories/tpack/tpack}
% \usepackage{C:/Users/Admin-PC/Documents/git_repository/tpack/tpack}
\usepackage{/home/tr0fin0/Documents/git_repositories/tpack/tpack}
% \usepackage{/home/Documents/git_repositories/tpack/tpack}
\usetikzlibrary{decorations.pathreplacing,calligraphy}

\title{OS202 - Programming Parallel Computers}
\project{Travail Dirigée}
\author{Guilherme Nunes Trofino}
\authorRA{2022-2024}


\makeatletter
\begin{document}\selectlanguage{french}
\maketitle
\setlength{\parindent}{0pt}

\newcommand{\tableN}[2]{
    \begin{table}[H]
        \centering\begin{tabular}{lrl}
            n & secondes & MFloops\\
            \hline\hline
            #2
        \end{tabular}
        \caption{\texttt{#1}}
    \end{table}
}



\newpage\tableofcontents

\section{Introduction}
% \subfile{C:/Users/guitr/Documents/git_repositories/classes_ensta/intro.tex}
% \subfile{C:/Users/Admin-PC/Documents/git_repository/classes_ensta/intro.tex}
\subfile{/home/tr0fin0/Documents/git_repositories/classes_ensta/intro.tex}
% \subfile{/home/Documents/git_repositories/classes_ensta/intro.tex}


\subsection{Information Matier}
\paragraph{Référence}Dans cette matière le but sera de comprendre \title{}. Ce travail est sur \href{https://github.com/JuvignyEnsta/Course2023/blob/main/TravauxDirig%C3%A9s/TD_numero_1/Sujet.pdf}{https://github.com/} avec l'objectif d'étudier et démontrer l'augmentation de performance quand on utilise la programmation parallèle.

\subsection{Caracteristiques Ordinateur}
\paragraph{CPU}On utilisé le commande \texttt{lscpu} pour avoir des informations sur le processeur de mon ordinateur en retournant le suivant:
\begin{scriptsize}
    % \mycode\lstinputlisting[language=bash]{example/main.cpp}
    \mycode
    \begin{lstlisting}[language=bash]
    Architecture:           x86_64
        CPU op-mode(s):         32-bit, 64-bit
        Address sizes:          39 bits physical, 48 bits virtual
        Byte Order:             Little Endian
        CPU(s):                 20
        On-line CPU(s) list:    0-19
        Vendor ID:              GenuineIntel
    Model name:            12th Gen Intel(R) Core(TM) i7-12700H
        CPU family:          6
        Model:               154
        Thread(s) per core:  2
        Core(s) per socket:  14
        Socket(s):           1
        Stepping:            3
        CPU max MHz:         4700.0000
        CPU min MHz:         400.0000
    \end{lstlisting}
\end{scriptsize}
On peut voir qui mon ordinateur a, théoriquement, 20 CPU's disponibles avec les mémoires suivants:
\begin{scriptsize}
    \mycode
    \begin{lstlisting}[language=bash]
    Caches (sum of all):     
        L1d:    544  KiB    (14 instances)
        L1i:    704  KiB    (14 instances)
        L2:     11.5 MiB    ( 8 instances)
        L3:     24   MiB    ( 1 instance)
    \end{lstlisting}
\end{scriptsize}
Ces données seront utilisés pour l'analyse des performances. 

% chercher hyperthreading
% essayer avec la librairie #pragemomp parallel for
% #pragma omp parallel for ... parallelise les for au dessous de la ligne de pragma
% BLAS libraire pour faire mieux les operations de multiplication de matrice en considerant les caracteristiques de l'ordinateur


\section{Produit Matrice-Matrice}
\subsection*{Question 1}
\begin{resolution}
    Les tailles suivants on était essayés:
    \tableN{ijk}{
        1023 & 1.17911 & 1815.94\\
        1024 & 2.89563 &  741.63\\
        1025 & 1.22712 & 1755.14\\
        2047 &  9.9369 & 1726.37\\
        2048 & 33.1686 & 517.956\\
        2049 & 10.2921 & 1671.68\\\hline
        avg & 9.7832 & 1371.45\\
    }
    On note qu'il y a une grand différence entre l'exécution avec une matrix de taille égale à une puissances de 2.\\

    Ce comportement peut être justifié avec la façon que la mémoire est gérer pour la CPU et pour la construction de la mémoire.\\

    Quand on utilise une variable à la position \texttt{i} c'est commun d'utiliser la variable à la position \texttt{i+1}. Le CPU considère ce principe et enregistre des variables en sequence.\\

    La mémoire est construit à partir des structures binaires donc elle aura une taille multiple de 2. Son addressage sera fait à partir du module de la taille de la mémoire.\\

    Quand il y a une matrice d'une taille multiple de 2, le module se rendre toujours au même endroit et donc chaque fois qui le CPU veut enregistre une variable il faut recopier tous les données en prenant plus de temps.
\end{resolution}

\newpage\subsection*{Question 2}
\begin{resolution}
    On considère que la multiplication de 2 matrices sera fait avec les variables \texttt{i j k}:
    \begin{scriptsize}
        \mycode
        \begin{lstlisting}[language=C++]
    C(i, j) += A(i, k) * B(k, j)
        \end{lstlisting}
    \end{scriptsize}
    Les tableaux suivants représentent le temps necessaires pour calculer la multiplication avec des différents configurations de \texttt{loop}:
    \begin{center}
        \begin{minipage}[b]{0.3\textwidth}
            \tableN{ijk}{
                1023 & 1.17911 & 1815.94\\
                1024 & 2.89563 &  741.63\\
                1025 & 1.22712 & 1755.14\\
                2047 &  9.9369 & 1726.37\\
                2048 & 33.1686 & 517.956\\
                2049 & 10.2921 & 1671.68\\\hline
                avg & 9.7832 & 1371.45\\
            }
        \end{minipage}
        \begin{minipage}[b]{0.3\textwidth}
            \tableN{jik}{
                1023 & 1.26207 & 1696.58\\
                1024 & 3.01302 & 712.735\\
                1025 & 1.37956 & 1561.21\\
                2047 & 23.6272 & 726.057\\
                2048 & 70.8302 & 242.55\\
                2049 & 24.7906 & 694.016\\\hline
                avg & 20.8171 & 938.86\\
            }
        \end{minipage}
        \begin{minipage}[b]{0.3\textwidth}
            \tableN{jki}{
                1023 & 0.394346 & 5429.74\\
                1024 & 0.407676 & 5267.63\\
                1025 & 0.416262 & 5174.1\\
                2047 & 4.91225 & 3492.23\\
                2048 & 5.02442 & 3419.27\\
                2049 & 5.12015 & 3360.27\\\hline
                avg & 2.7125 & 4357.21\\
            }
        \end{minipage}
    \end{center}
    \begin{center}
        \begin{minipage}[b]{0.3\textwidth}
            \tableN{ikj}{
                1023 & 2.38203 & 898.897\\
                1024 & 7.31333 & 293.64\\
                1025 & 2.13751 & 1007.61\\
                2047 & 76.2133 & 225.088\\
                2048 & 109.086 & 157.489\\
                2049 & 73.7907 & 233.16\\\hline
                avg & 45.1538 & 469.31\\
            }
        \end{minipage}
        \begin{minipage}[b]{0.3\textwidth}
            \tableN{kij}{
                1023 & 2.27681 & 940.437\\
                1024 & 7.27702 & 295.105\\
                1025 & 2.52188 & 854.038\\
                2047 & 62.4818 & 274.555\\
                2048 & 132.456 & 129.702\\
                2049 & 73.0916 & 235.39\\\hline
                avg & 46.6842 & 454.87\\
            }
        \end{minipage}
        \begin{minipage}[b]{0.3\textwidth}
            \tableN{kji}{
                1023 & 0.571053 & 3749.56\\
                1024 & 0.462365 & 4644.56\\
                1025 & 0.454393 & 4739.91\\
                2047 & 5.77844 & 2968.75\\
                2048 & 5.63255 & 3050.11\\
                2049 & 5.69804 & 3019.47\\\hline
                avg & 3.0995 & 3695.39\\
            }
        \end{minipage}
    \end{center}
    L'ordre \texttt{jki} était la plus efficace: les operations on pris moins de temps et la différence entre une matrice de taille multiple de 2 et une autre matrice n'était pas très significative.\\

    Comment précise pour la question précédent les données de la mémoire sont enregistres en groupe donc l'ordre entre lignes et colognes va influencer le résultat.\\

    Code considère:
    \begin{scriptsize}
        \mycode
        \begin{lstlisting}[language=C++]
    for (int j = iColBlkB; j < std::min(B.nbCols, iColBlkB + szBlock); j++)
      for (int k = iColBlkA; k < std::min(A.nbCols, iColBlkA + szBlock); k++)
        for (int i = iRowBlkA; i < std::min(A.nbRows, iRowBlkA + szBlock); ++i)
          C(i, j) += A(i, k) * B(k, j);
        \end{lstlisting}
    \end{scriptsize}
    On peut voir:
    \begin{enumerate}[noitemsep]
        \item \texttt{i} représente les lignes;
        \item \texttt{j} représente les colognes;
    \end{enumerate}
    Comment l'algorithme est plus rapide quand l'interation "plus frequente" est sur \texttt{i} ça veut dire que les données sont estoquées pour lignes.
    % TODO confirm interpretation

    % \tableN{}{
    %     1023 &  & \\
    %     1024 &  & \\
    %     1025 &  & \\
    % }{
    %     2047 &  & \\
    %     2048 &  & \\
    %     2049 &  & \\
    % }
\end{resolution}

\newpage\subsection*{Question 3}
\begin{resolution}
    Les tableaux suivants représentent le temps necessaires pour calculer la multiplication avec l'ordre la plus efficace du \texttt{loop}, \texttt{jki}, et une quantité n de threads représentes par \texttt{[n]}:
\begin{center}
    \begin{minipage}[b]{0.3\textwidth}
        \tableN{jki [1]}{
            1023 & 0.0970206 & 22069.5\\
            1024 & 0.101690 & 21118.0\\
            1025 & 0.110316 & 19523.8\\
            2047 & 0.557667 & 30761.6\\
            2048 & 0.455107 & 37749.1\\
            2049 & 0.491632 & 34995.8\\\hline
            avg & 0.3022 & 27702.97\\
        }
    \end{minipage}
    \begin{minipage}[b]{0.3\textwidth}
        \tableN{jki [4]}{
            1023 & 0.102490 & 20891.8\\
            1024 & 0.0908985 & 23625.1\\
            1025 & 0.119587 & 18010.2\\
            2047 & 0.497154 & 34505.9\\
            2048 & 0.570854 & 30095.0\\
            2049 & 0.500602 & 34368.7\\\hline
            avg & 0.3149 & 26916.12\\
        }
    \end{minipage}
    \begin{minipage}[b]{0.3\textwidth}
        \tableN{jki [8]}{
            1023 & 0.0997595 & 21463.6\\
            1024 & 0.119725 & 17936.8\\
            1025 & 0.105947 & 20328.8\\
            2047 & 0.513362 & 33416.4\\
            2048 & 0.471373 & 36446.5\\
            2049 & 0.475105 & 36213.1\\\hline
            avg & 0.2975 & 27634.2\\
        }
    \end{minipage}
\end{center}
\begin{center}
    \begin{minipage}[b]{0.3\textwidth}
        \tableN{jki [12]}{
            1023 & 0.0961568 & 22267.8\\
            1024 & 0.0929003 & 23116.0\\
            1025 & 0.0865847 & 24874.8\\
            2047 & 0.513362 & 31964.4\\
            2048 & 0.479124 & 35856.8\\
            2049 & 0.486361 & 35375.1\\\hline
            avg & 0.2924 & 28909.15\\
        }
    \end{minipage}
    \begin{minipage}[b]{0.3\textwidth}
        \tableN{jki [16]}{
            1023 & 0.0848282 & 25241.6\\
            1024 & 0.0990637 & 21677.8\\
            1025 & 0.121633 & 17707.3\\
            2047 & 0.513362 & 31244.3\\
            2048 & 0.439260 & 39110.9\\
            2049 & 0.483793 & 35561.8\\\hline
            avg & 0.2903 & 28423.95\\
        }
    \end{minipage}
    \begin{minipage}[b]{0.3\textwidth}
        \tableN{jki [20]}{
            1023 & 0.0998027 & 21454.3\\
            1024 & 0.110846 & 19373.5\\
            1025 & 0.108874 & 19782.3\\
            2047 & 0.568054 & 30199.1\\
            2048 & 0.473769 & 36262.1\\
            2049 & 0.493240 & 34881.7\\\hline
            avg & 0.3091 & 26992.17\\
        }
    \end{minipage}
\end{center}
On peut voir que l'utilisation de threads a rendu l'exécution du programme: 8.9758, 8.6138, 9.1176, 9.2767, 9.3438 et 8.7755 fois plus rapide pour 1, 4, 8, 12, 16 et 20 threads respectivement.\\

Quand une nouvelle thread est crée on gagne la capacité de faire plusieurs calcules au même temps sur différents parties du processeur au prix d'avoir moins de mémoire pour chaque thread car la quantité de mémoire disponible reste constant.\\

De cette façon, on peut voir que 16 était la configuration la plus rapide pour faire les calcules.\\

Code considère:
\begin{scriptsize}
    \mycode
    \begin{lstlisting}[language=C++]
#pragma omp parallel  // parallel declaration
{
int i, j, k;
omp_set_num_threads(8);
#pragma omp for     // declare for function as parallel
for (j = iColBlkB; j < std::min(B.nbCols, iColBlkB + szBlock); j++)
  for (k = iColBlkA; k < std::min(A.nbCols, iColBlkA + szBlock); k++)
    for (i = iRowBlkA; i < std::min(A.nbRows, iRowBlkA + szBlock); ++i)
      C(i, j) += A(i, k) * B(k, j);
const int szBlock = 32;
}
    \end{lstlisting}
\end{scriptsize}

Informations utiles étaient prises de le site suivant: \href{https://stackoverflow.com/questions/22634121/openmp-c-matrix-multiplication-run-slower-in-parallel}{https://stackoverflow.com/}
\end{resolution}

\subsection*{Question 4}
\begin{resolution}
    C'est bien sur possible d'avoir une amélioration encore plus significative car ici on a optimisé une parametre à la fois sans considérer tous combinations possibles pour chaque variable.
\end{resolution}

\newpage\subsection*{Question 5}
\begin{resolution}
    Les tableaux suivants représentent le temps necessaires pour calculer la multiplication avec des différents configurations de \texttt{loop}:
    \begin{center}
        \begin{minipage}[b]{0.3\textwidth}
            \tableN{mnjki [16]}{
                1024 & 0.842497 & 2548.95\\
                2048 & 7.283589 & 2358.71\\
                \hline
                avg  & 4.063043 & 2453.83\\
            }
        \end{minipage}
        \begin{minipage}[b]{0.3\textwidth}
            \tableN{mnjki [64]}{
                1024 & 0.655394 & 3276.63\\
                2048 & 5.342796 & 3215.52\\
                \hline
                avg  & 2.999095 & 3246.08\\
            }
        \end{minipage}
        \begin{minipage}[b]{0.3\textwidth}
            \tableN{mnjki [256]}{
                1024 & 0.552740 & 3885.16\\
                2048 & 4.578990 & 3751.89\\
                \hline
                avg  & 2.565865 & 3818.53\\
            }
        \end{minipage}
    \end{center}

    \begin{center}
        \begin{minipage}[b]{0.3\textwidth}
            \tableN{nmjki [16]}{
                1024 & 0.812334 & 2643.60\\
                2048 & 7.745882 & 2217.94\\
                \hline
                avg  & 4.279108 & 2430.77\\
            }
        \end{minipage}
        \begin{minipage}[b]{0.3\textwidth}
            \tableN{nmjki [64]}{
                1024 & 0.656772 & 3269.75\\
                2048 & 5.463736 & 3144.34\\
                \hline
                avg  & 3.060254 & 3207.05\\
            }
        \end{minipage}
        \begin{minipage}[b]{0.3\textwidth}
            \tableN{nmjki [256]}{
                1024 & 0.550865 & 3898.38\\
                2048 & 4.661620 & 3685.39\\
                \hline
                avg  & 2.606242 & 3791.89\\
            }
        \end{minipage}
    \end{center}

    On peut voir que la configuration \texttt{nmjki} est l'ordre de \texttt{loop} la plus efficace et 256 comme taille de bloque.\\

    Code considère:
    \begin{scriptsize}
        \mycode
        \begin{lstlisting}[language=C++]
{
int dim = std::max({A.nbRows, B.nbCols, A.nbCols});

int m, n, i, j, k;

for (m = 0; m < dim; m+=sizeBlock)
    for (n = 0; n < dim; n+=sizeBlock)
        for (j = n; j < n+sizeBlock; j++)
        for (k = 0; k < dim; k++)
            for (i = m; i < m+sizeBlock; i++)
                C(i, j) += A(i, k) * B(k, j);
}
        \end{lstlisting}
    \end{scriptsize}
\end{resolution}

\newpage\subsection*{Question 6}
\begin{resolution}
    On peut voir que l'utilisation des bloques rendre le programme aussi plus efficace que quand compare à la même configuration séquentielle sans parallélisme.\\

    Ici seulement les tailles 1024 et 2048 étaient considères car, pour la division en bloques le code a besoin des tailles divisibles pour une valeur commun.
\end{resolution}

\newpage\subsection*{Question 7}
\begin{resolution}
    Les tableaux suivants représentent le temps necessaires pour calculer la multiplication avec des différents tailles de bloque représentes par \texttt{[s]} avec la configuration de \texttt{loop} la plus efficace, \texttt{nmjki}:
    \begin{center}
        \begin{minipage}[b]{0.3\textwidth}
            \tableN{nmjki [16]}{
                1024 & 0.165874 & 12946.51\\
                2048 & 1.252230 & 13719.42\\
                \hline
                avg  & 0.709052 & 13332.97\\
            }
        \end{minipage}
        \begin{minipage}[b]{0.3\textwidth}
            \tableN{nmjki [32]}{
                1024 & 0.159252 & 13484.84\\
                2048 & 1.128784 & 15219.81\\
                \hline
                avg  & 0.644018 & 14352.32\\
            }
        \end{minipage}
        \begin{minipage}[b]{0.3\textwidth}
            \tableN{nmjki [64]}{
                1024 & 0.125556 & 17103.75\\
                2048 & 0.950782 & 18069.19\\
                \hline
                avg  & 0.538169 & 17586.47\\
            }
        \end{minipage}
    \end{center}

    \begin{center}
        \begin{minipage}[b]{0.3\textwidth}
            \tableN{nmjki [128]}{
                1024 & 0.134669 & 15946.42\\
                2048 & 0.674998 & 25451.72\\
                \hline
                avg  & 0.404833 & 20699.07\\
            }
        \end{minipage}
        \begin{minipage}[b]{0.3\textwidth}
            \tableN{nmjki [256]}{
                1024 & 0.175878 & 12210.04\\
                2048 & 0.771701 & 22262.34\\
                \hline
                avg  & 0.473790 & 17236.19\\
            }
        \end{minipage}
        \begin{minipage}[b]{0.3\textwidth}
            \tableN{nmjki [512]}{
                1024 & 0.263427 & 8152.11\\
                2048 & 1.064857 & 16133.50\\
                \hline
                avg  & 0.664142 & 12142.80\\
            }
        \end{minipage}
    \end{center}

    On peut voir que même avec l'utilisation des bloques l'exécution du code n'était pas plus efficace. Ici la quantité de threads utilise, 16, pourrait-être pas idéale pour le système.\\

    Code considère:
    \begin{scriptsize}
        \mycode
        \begin{lstlisting}[language=C++]
#pragma omp parallel        // parallel declaration
{
int dim = std::max({A.nbRows, B.nbCols, A.nbCols});

int m, n, i, j, k;
omp_set_num_threads(16);

#pragma omp for
for (n = 0; n < dim; n+=sizeBlock)
    for (m = 0; m < dim; m+=sizeBlock)
        for (j = n; j < n+sizeBlock; j++)
            for (k = 0; k < dim; k++)
                for (i = m; i < m+sizeBlock; i++)
                    C(i, j) += A(i, k) * B(k, j);
}
        \end{lstlisting}
    \end{scriptsize}
\end{resolution}

\newpage\subsection*{Question 8}
\begin{resolution}
    Le makefile n'arrivait pas à créer le .exe pour faire cette essayé.
\end{resolution}


\section{Parallélisation MPI}
\subsection{Circulation}

partie 2
tous les questions sont dans les examples et propablement sur youtube, pas trop difficile a faire
\begin{scriptsize}
    \mycode\lstinputlisting[language=Python]{MPI.py}
\end{scriptsize}



\newpage\subsection{Calcul $\pi$}

\begin{resolution}
    Le calcul de $\pi$ propose est expliqué et implémenté sur le vidéo: \href{https://www.youtube.com/watch?v=prPyPvjvfqM}{Inside Code}.\\

    On considère le code suivant:
    \begin{scriptsize}
        \mycode\lstinputlisting[language=Python, linerange={1-5}]{PI.py}
    \end{scriptsize}
    Observation, pour y accéder il suifit clique sur le code. En comparant les résultats de chaque exécution on aura:
    \begin{scriptsize}
        \mycode
        \begin{lstlisting}[language=bash]
    pi: 3.141774 error: 0.000182
    serial: 0.529775 s

    CPUs: 20
    pi: 3.148800 error: 0.007207
    parrel: 0.025772 s
        \end{lstlisting}
    \end{scriptsize}
    Dans cette essayé 1e4 points étaient utilisés pour estimer Pi. On peut voir que le code parallèle a été 20.56 fois plus rapide que la version séquentielle.\\

    \begin{scriptsize}
        \mycode
        \begin{lstlisting}[language=bash]
    pi: 3.141522 error: -0.000070
    serial: 73.425146 s
    
    CPUs: 20
    pi: 3.161720 error: 0.020127
    parrel: 0.024069 s
        \end{lstlisting}
    \end{scriptsize}
    Dans cette essayé 1e5 points étaient utilisés pour estimer Pi. On peut voir que le code parallèle a été 3050.61 fois plus rapide que la version séquentielle.\\

    On peut voir que la version parallèle est beaucoup plus rapide en temps d'exécution par contre son erreur est plus significative car au lieu d'avoir une grande quantité de points chaque CPU aura une quantité réduit. On essayé la version de blocs avec 1e8 points et on trouve:
    \begin{scriptsize}
        \mycode
        \begin{lstlisting}[language=bash]
    CPUs: 20
    pi: 3.141279 error: -0.000313
    parrel: 0.625430 s
        \end{lstlisting}
    \end{scriptsize}
    Maintenant, avec beaucoup plus de points par thread, on trouvé une résultat plus précis et avec un temps de calcule plus modeste.
\end{resolution}

\newpage\subsection*{Question 3}
\begin{resolution}
    
\end{resolution}

\newpage\subsection{Hypercube}
\begin{resolution}
    
\end{resolution}


\end{document}