{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/achanhon/coursdeeplearningcolab/blob/master/cnn_mnist.ipynb","timestamp":1670492159993}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","metadata":{"id":"UTUF2gpAcOr5"},"source":["# Deep Learning\n","\n","Execution -> Change Execution Type -> GPU"]},{"cell_type":"markdown","metadata":{"id":"UGNwRuVjdE5W"},"source":["## Inicialization\n","---"]},{"cell_type":"code","metadata":{"id":"ouvhsCnwdPgm","executionInfo":{"status":"ok","timestamp":1670492484310,"user_tz":-60,"elapsed":4781,"user":{"displayName":"Guilherme Trofino","userId":"06751314715112559914"}}},"source":["# PyTorch:  https://pytorch.org/\n","import torch\n","import torch.nn as nn           # Neural Network\n","import torch.nn.functional as F # Convolution Functions\n","import torch.optim as optim     # Optimization Algorithms\n","import torchvision              # Package for Computer Vision:\n","                                #   - popular datasets;\n","                                #   - model architectures;\n","                                #   - common image transformations;\n","\n","# NumPy:    https://numpy.org/\n","import numpy as np\n","\n","# MathPlot: https://numpy.org/\n","import matplotlib.pyplot as plt"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"GBPJ5pdmdghW"},"source":["transform_mnist = torchvision.transforms.Compose([\n","    torchvision.transforms.Resize((32,32)),\n","    torchvision.transforms.ToTensor()\n","])\n","\n","mnisttrain = torchvision.datasets.MNIST(\"./mnist\",train=True, transform=transform_mnist, download=True)\n","trainloader = torch.utils.data.DataLoader(mnisttrain, batch_size=64, shuffle=True, num_workers=2)\n","\n","mnisttest = torchvision.datasets.MNIST(\"./mnist\",train=False, transform=transform_mnist, download=True)\n","testloader = torch.utils.data.DataLoader(mnisttest, batch_size=64, shuffle=True, num_workers=2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Neural Network Linear"],"metadata":{"id":"ITd7Xb1RZOKG"}},{"cell_type":"code","metadata":{"id":"lUPT6Psfd4K8","executionInfo":{"status":"ok","timestamp":1670492628741,"user_tz":-60,"elapsed":7394,"user":{"displayName":"Guilherme Trofino","userId":"06751314715112559914"}}},"source":["class MonReseau(nn.Module):\n","    def __init__(self):\n","        super(MonReseau, self).__init__()   # search super\n","        \n","        self.linear1 = nn.Linear(1024, 1024)\n","        self.linear2 = nn.Linear(1024, 2048)\n","        self.linear3 = nn.Linear(2048, 4096)\n","\n","        self.final = nn.Linear(4096,10)\n","      \n","    def forward(self, x):\n","        x = x.view(-1,1024)  # l'image 1 x 32 x 32 devient un vecteur 1024\n","        x = F.leaky_relu(self.linear1(x))   # search leaky_relu\n","        x = F.leaky_relu(self.linear2(x))\n","        x = F.leaky_relu(self.linear3(x))\n","        \n","        x = self.final(x)\n","        return x\n","\n","\n","monreseau = MonReseau()\n","monreseau = monreseau.cuda()\n","\n","optimizer = optim.Adam(monreseau.parameters(), lr=0.00001)\n","criterion = nn.CrossEntropyLoss()\n","nbepoch = 5"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["### Neural Network Convolutional"],"metadata":{"id":"j144_4pNZe2x"}},{"cell_type":"code","metadata":{"id":"t0UVDKw2opzd"},"source":["class MonReseau(nn.Module):\n","    def __init__(self):\n","        super(MonReseau, self).__init__()   # search super\n","        \n","        self.conv1 = nn.Conv2d(1,  32, kernel_size=5, padding=2)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n","        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n","\n","        self.final = nn.Linear(4096,10)\n","      \n","    def forward(self, x):                               # l'image:\n","        x = F.leaky_relu(self.conv1(x))                 #  1x32x32 -> 32x32x32\n","        x = F.max_pool2d(x, kernel_size= 2, stride=2)   #          -> 32x16x16\n","        \n","        x = F.leaky_relu(self.conv2(x))                 #          -> 64x16x16\n","        x = F.max_pool2d(x, kernel_size= 2, stride=2)   #          -> 64x08x08\n","        \n","        x = F.leaky_relu(self.conv3(x))                 #          -> 64x08x08\n","        \n","        x = x.view(-1,4096)                             #          -> 64x08x08\n","        \n","        x = self.final(x)\n","        return x\n","\n","\n","monreseau = MonReseau()\n","monreseau = monreseau.cuda()\n","\n","optimizer = optim.Adam(monreseau.parameters(), lr=0.00001)\n","criterion = nn.CrossEntropyLoss()\n","nbepoch = 5"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iauL3XSqfISU"},"source":["## Visualization\n","---"]},{"cell_type":"code","metadata":{"id":"a5GqZNlohsM3"},"source":["def show(img):\n","    npimg = img.numpy()\n","    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n","\n","sample = next(iter(trainloader))[0]\n","show(torchvision.utils.make_grid(sample))\n","print(sample.shape)     ## 64 c'est le batch\n","                        ## 1 c'est du gris -- sinon ce serait 3 pour du RGB\n","                        ## 32x32 c'est pour la taille de l'image (petite ici)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M3kDmxkRkODf"},"source":["## Trainning\n","---"]},{"cell_type":"code","metadata":{"id":"T7IU7veee3f6"},"source":["import random\n","\n","\n","for epoch in range(nbepoch):\n","    monreseau.train()\n","    print(\"epoch\", epoch)\n","\n","    for inputs, targets in trainloader: ## on itere sur les données \n","        inputs, targets = inputs.cuda(),targets.cuda()\n","\n","        mespredictions = monreseau(inputs)      ## on les fait rentrer dans le réseau\n","        loss = criterion(mespredictions,targets)## on compare la sortie courante à la sortie voulue\n","\n","        optimizer.zero_grad()   ## supprime les gradients courants\n","        loss.backward()         ## le gradient -- la magie par rapport à comment c'était long en court :-)\n","        optimizer.step()        ## on actualise les poids pour que la sortie courante soit plus proche que la sortie voulue\n","\n","        if random.randint(0,90)==0:\n","            print(\"\\tloss=\",loss)   ## on affiche pour valider que ça diverge pas"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tiCrUvECoTsx"},"source":["Maintenant, on calcule la performance obtenue **en test**\n","à travers la matrice de confusion\n","Mij c'est le nombre de fois qu'une image de la classe i a été classé comme j"]},{"cell_type":"markdown","source":["## Analysis\n","---"],"metadata":{"id":"u1t8FogWZFl5"}},{"cell_type":"code","metadata":{"id":"XUl-2z9FfRUG"},"source":["from sklearn.metrics import confusion_matrix\n","\n","monreseau.eval()\n","cm = np.zeros((10,10), dtype=int)        ## ATTENTION DE BIEN ME REMETTRE A ZERO\n","with torch.no_grad():                   ## ici pas besoin de calculer les gradients\n","    for inputs, targets in testloader:\n","        inputs = inputs.cuda()\n","        outputs = monreseau(inputs)\n","        _,pred = outputs.max(1)\n","        cm += confusion_matrix(pred.cpu().numpy(),targets.cpu().numpy(),labels =list(range(10)))\n","\n","print(cm)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0XlQ7IltqA-o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670494539033,"user_tz":-60,"elapsed":847,"user":{"displayName":"Guilherme Trofino","userId":"06751314715112559914"}},"outputId":"255b2191-9f37-4fe1-c875-7a89f0a704e8"},"source":["def evaluateClassification(classification):\n","    evaluation = np.zeros( (classification.shape[0]), dtype = float)\n","\n","    total = classification.sum()\n","    for i in range(classification.shape[0]):\n","        evaluation[i] = classification[i,i] / total\n","\n","    return evaluation\n","\n","\n","print(evaluateClassification(cm))"],"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.0964 0.1118 0.098  0.0968 0.0937 0.0839 0.0927 0.0981 0.0865 0.0941]\n"]}]},{"cell_type":"markdown","metadata":{"id":"L82jBjtP-vwr"},"source":["# CNN VS MLP\n","\n","Maintenant on va s'intéresser à la différence entre un mlp et un CNN\n","\n","\n","on fait regarder ce que donne nos codes -- si on permute les pixels\n","ce sera évidemment une permutation **FIXE** (ce sera la même pour toutes les images train et test) qu'on peut générer calculant une permutation des lignes et une des colonnes"]},{"cell_type":"code","metadata":{"id":"jb5cc28A_B4K"},"source":["def computerandompermutation(n):\n","\tout = list(range(n))\n","\trandom.shuffle(out)\n","\treturn out\n","permrow,permcol = computerandompermutation(32),computerandompermutation(32)\n","print(permrow)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OC2xtwaYsYxV"},"source":["\n","\n","**Q3 (moyenne) :** Coder une fonction qui prends en argument une permutation et une image et qui permute ses pixels.\n","\n","\n","*n'oubliez est pour permuter la valeur de x et y dans un tableau T il faut faire*\n","- tmp = T[y]\n","- T[y] = T[x]\n","- T[x] = tmp\n","\n","(sinon on écrase une des 2 valeurs)\n","\n","commencer par permuter une image 32x32 et créer une fonction qui l'applique 64 fois sur un batch 64x1x32x32"]},{"cell_type":"code","metadata":{"id":"cyE-3bjp_TY8"},"source":["print(\"TODO\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6QfvV_3e_Sp_"},"source":["**SIGNALEZ que vous avez fini la question ci dessus -- il est nécessaire d'utiliser un codage efficace des permutations pour continuer -- il vous sera fourni**\n","\n","\n","**Q4 (facile) :**\n","Regarder les images avant et après permutation -- pourriez vous (vous même) classer les images APRES permutation ??\n"]},{"cell_type":"code","metadata":{"id":"sJWQUZmLEorH"},"source":["print(\"TODO\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"13gMLc6AEniu"},"source":["**Q5 (facile)** :\n","Qu'est ce que ça change pour le MLP ??\n","-> relancer l'apprentissage/test en ajoutant cette permutation pour valider que ça ne change rien !\n"]},{"cell_type":"code","metadata":{"id":"iUGDT9osEnU4"},"source":["print(\"TODO\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WUshMI-dEnIu"},"source":["**Q6 (facile)** : relancer le lenet -> là ça va changer "]},{"cell_type":"code","metadata":{"id":"2ds_JZ4aupBC"},"source":["print(\"TODO\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"laPww2Bnurqy"},"source":["**Q7 (moyenne) :** faites une fonction qui ajoute du bruit (pour chaque pixel, mettez le à 0 ou à 1 avec une petite probabilité - le bruit est différent pour chaque image train et test)\n"]},{"cell_type":"code","metadata":{"id":"-caGUzxVE5Hs"},"source":["print(\"TODO\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QJzlLXTAEyql"},"source":["**Q8 (facile)** : Regarder les images avant et après permutation -- pourriez vous (vous même) classer les images APRES permutation ??\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"cGiAvpKQEyh9"},"source":["print(\"TODO\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CekiyPfhEz2U"},"source":["**Q9 (facile)** : Tester le MLP et le CNN -> cette fois c'est le CNN qui devrait être \"plutôt\" invariant (le bruit est +/- filtré par la convolution) alors que le MLP devrait être gêné par le bruit !"]},{"cell_type":"code","metadata":{"id":"WTA3zrQyxphh"},"source":["print(\"TODO\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QYYZMfsixq7g"},"source":["## conclusion\n","\n","**-> se souvenir que si on prend TOUS les problèmes, tous les algos de classification sont tous aussi mauvais**\n","\n","**-> ce qui compte c'est qu'ils soient adaptés aux données qu'on peut réellement rencontrer**\n","\n","**En comparant les images avec permutation des pixels vs avec un bruit... Vous pouvez comprendre pourquoi le CNN est plus adapté à l'image naturelle \n","que le MLP !**"]}]}