\documentclass{article}
\usepackage{C:/Users/guitr/Documents/git_repositories/tpack/tpack}
% \usepackage{C:/Users/Admin-PC/Documents/git_repository/tpack/tpack}
% \usepackage{/home/tr0fin0/git_repositories/tpack/tpack}


\title{MI201 - Apprentissage Automatique}
\project{Résumé Théorique}
\author{Guilherme Nunes Trofino}
\authorRA{2022-2024}


\makeatletter
\begin{document}\selectlanguage{french}
\maketitle
\setlength{\parindent}{0pt}


\newpage\tableofcontents

\section{Introduction}
\subfile{C:/Users/guitr/Documents/git_repositories/classes_ensta/intro.tex}
% \subfile{C:/Users/Admin-PC/Documents/git_repository/classes_ensta/intro.tex}
% \subfile{/home/tr0fin0/git_repositories/classes_ensta/intro.tex}


\subsection{Information Matier}
\paragraph{Référence}
\url{https://cs231n.github.io/python-numpy-tutorial/}


\section{Classification}

\subsection{Supervised Learning}
\subsubsection{kNN, k Nearest Neighbours}
\subsubsection{Decision Trees}
\subsubsection{SVM, Support Vector Machines}
\subsubsection{Neural Networks}

\subsection{Semi-Supervised Learning}
\subsubsection{Linear Regression}

\subsection{Unsupervised Learning}
\subsubsection{k-Means Clustering}


\subsection{Reinforcement Learning}


\section{Apprentissage}
L'apprentissage automatique est une démarche de conception d'un prédicteur et par une modélisation ou programmation non explicité à partir d'exemples.

\subsection{Algorithme}
On considère que l'algorithme peut être définie par la définition suivante:
\begin{definition}
    Generative Model;
    Discriminative Model;
\end{definition}

Généralement on aura le comportement suivant:
\begin{table}[H]
    \centering\begin{tabular}{lll}
        k $\uparrow  $ & biais $\uparrow  $ & variance $\downarrow$\\
        k $\downarrow$ & biais $\downarrow$ & variance $\uparrow$\\
    \end{tabular}
    \caption{Comportement Neural Network}
\end{table}

\subsubsection{Avantages}
Dans ce cas, cet algorithme 

\subsubsection{Incovenients}
Dans ce cas, cet algorithme 

\subsubsection{Applications}
Cet algorithme est souvent utilisé 


\subsection{Initialization}
\subsection{Visualization}
caractéristiques sont des features
\subsection{Training}



\section{Prédiction}
\subsection{Analyses}
Parmi les possibilités d'évaluation la plus simple c'est le Taux d'Erreur Moyen:
\begin{definition}
    \begin{equation}
        \boxed{
            e = \frac{\text{nombre d'étiquettes erronées}}{\text{nombre total de données}}
        }
    \end{equation}
\end{definition}

\subsubsection{Confusion Matrix}
Util qui permet de visualizer la performance d'un algorithme, généralement supervisé, défini par le suivant:
\begin{definition}
    Table qui permet de visualizer les prévisions d'un algorithme:
    \begin{equation}
        \boxed{
            \mathcal{M} = 
            \begin{bmatrix}
                m_{00} & \cdots & m_{0j} & \cdots & m_{0n}\\
                \vdots & \ddots & \vdots & \ddots & \vdots\\
                m_{i0} & \cdots & m_{ij} & \cdots & m_{in}\\ 
                \vdots & \ddots & \vdots & \ddots & \vdots\\
                m_{n0} & \cdots & m_{nj} & \cdots & m_{nn}\\ 
            \end{bmatrix}
        }
    \end{equation}
    Où:
    \begin{enumerate}[noitemsep]
        \item $i$: chaque ligne représente des instances de la classe actuelle;
        \item $j$: chaque colonne représente des instances de la classe de prévision;
    \end{enumerate}
    Quand on considère que les données avaient $n$ caractéristiques.
    \begin{remark}
        Dans un bon résultat:
        \begin{equation*}
            m_{ij} \to 
            \begin{cases}
                0 & \forall i\neq j\\
                N\in\mathbb{N} & \forall i= j\\
            \end{cases}
        \end{equation*}
    \end{remark}
\end{definition}

\subsubsection{Validation Croisée}
\subsubsection{Dilemme Biais-Variance}

\subsubsection{Surapprentissage}
Quand on balance le Biais et la Variance il faut toujours considère le Surapprentissage, Over-Fitting:
\begin{definition}
    Quand le modèle proposé est très spécialise, apprend pas coeur les données de traînement, et portant est mauvais pour la généralisation des données de validation.
\end{definition}
C'est indésirable et donc il faut toujours l'éviter. À ce propos on peut:
\begin{enumerate}[noitemsep, rightmargin = \leftmargin]
    \item \textbf{Data Augmentation}:
    \begin{definition}
        Ajouter des données pour l'apprentissage.
    \end{definition}
    \item \textbf{Reduced Complexity}:
    \begin{definition}
        Réduire le nombre de caractéristiques considères pour l'apprentissage.
    \end{definition}
    On peut le faire en:
    \begin{enumerate}[noitemsep]
        \item early stopping;
    \end{enumerate}
\end{enumerate}
\end{document}