\documentclass{article}
\usepackage{C:/Users/guitr/Documents/git_repositories/tpack/tpack}
% \usepackage{C:/Users/Admin-PC/Documents/git_repository/tpack/tpack}
% \usepackage{/home/tr0fin0/git_repositories/tpack/tpack}


\title{MI201 - Apprentissage Automatique}
\project{Résumé Théorique}
\author{Guilherme Nunes Trofino}
\authorRA{2022-2024}


\makeatletter
\begin{document}\selectlanguage{french}
\maketitle
\setlength{\parindent}{0pt}


\newpage\tableofcontents

\section{Introduction}
\subfile{C:/Users/guitr/Documents/git_repositories/classes_ensta/intro.tex}
% \subfile{C:/Users/Admin-PC/Documents/git_repository/classes_ensta/intro.tex}
% \subfile{/home/tr0fin0/git_repositories/classes_ensta/intro.tex}


\subsection{Information Matier}
\paragraph{Référence}
\url{https://cs231n.github.io/python-numpy-tutorial/}


\section{Classification}

\subsection{Supervised Learning}
\subsubsection{kNN, k Nearest Neighbours}
La choix de k déterminera la qualité de la prédiction. Si on augmente k la qualité de la prediction améliore et le sur-apprentissage diminue. Généralement on aura le comportement suivant:
\begin{table}[H]
    \centering\begin{tabular}{lll}
        k $\uparrow  $ & biais $\uparrow  $ & variance $\downarrow$\\
        k $\downarrow$ & biais $\downarrow$ & variance $\uparrow$\\
    \end{tabular}
    \caption{Comportement kNN}
\end{table}

\subsubsection{Decision Trees}
La choix de la profondeur p de l'Arbre de Décision déterminera la qualité de la prédiction. Si on augment p la prediction améliore. Généralement on aura le comportement suivant:
\begin{table}[H]
    \centering\begin{tabular}{lll}
        p $\uparrow$   & biais $\downarrow$ & variance $\uparrow$\\
        p $\downarrow$ & biais $\uparrow  $ & variance $\downarrow$\\
    \end{tabular}
    \caption{Comportement Decision Tree}
\end{table}

\subsubsection{SVM, Support Vector Machines}
Généralement on aura le comportement suivant:
\begin{table}[H]
    \centering\begin{tabular}{rlll}
        merge rigide & C $\uparrow$   & biais $\downarrow$ & variance $\uparrow$\\
        merge soupe  & C $\downarrow$ & biais $\uparrow  $ & variance $\downarrow$\\
    \end{tabular}
    \caption{Comportement SVM}
\end{table}

\subsubsection{Neural Networks}
La choix de n déterminera la qualité de la prédiction. Si on réduire n la qualité de la prediction améliore et le sur-apprentissage diminue. Généralement on aura le comportement suivant:
\begin{table}[H]
    \centering\begin{tabular}{lll}
        n $\uparrow$   & biais $\downarrow$ & variance $\uparrow$\\
        n $\downarrow$ & biais $\uparrow  $ & variance $\downarrow$\\
    \end{tabular}
    \caption{Comportement Neural Network}
\end{table}

\subsection{Semi-Supervised Learning}
\subsubsection{Linear Regression}

\subsection{Unsupervised Learning}
\subsubsection{k-Means Clustering}


\subsection{Reinforcement Learning}


% \section{Apprentissage}
% L'apprentissage automatique est une démarche de conception d'un prédicteur et par une modélisation ou programmation non explicité à partir d'exemples.

% \subsection{Algorithme}
% On considère que l'algorithme peut être définie par la définition suivante:
% \begin{definition}
%     Generative Model;
%     Discriminative Model;
% \end{definition}

% Généralement on aura le comportement suivant:
% \begin{table}[H]
%     \centering\begin{tabular}{lll}
%         k $\uparrow  $ & biais $\uparrow  $ & variance $\downarrow$\\
%         k $\downarrow$ & biais $\downarrow$ & variance $\uparrow$\\
%     \end{tabular}
%     \caption{Comportement Neural Network}
% \end{table}

% \subsubsection{Avantages}
% Dans ce cas, cet algorithme 

% \subsubsection{Incovenients}
% Dans ce cas, cet algorithme 

% \subsubsection{Applications}
% Cet algorithme est souvent utilisé 


% \subsection{Initialization}
% \subsection{Visualization}
% caractéristiques sont des features
% \subsection{Training}



\section{Prédiction}
\subsection{Analyses}
Parmi les possibilités d'évaluation la plus simple c'est le Taux d'Erreur Moyen:
\begin{definition}
    \begin{equation}
        \boxed{
            e = \frac{\text{nombre d'étiquettes erronées}}{\text{nombre total de données}}
        }
    \end{equation}
\end{definition}

\subsubsection{Confusion Matrix}
Util qui permet de visualizer la performance d'un algorithme, généralement supervisé, défini par le suivant:
\begin{definition}
    Table qui permet de visualizer les prévisions d'un algorithme:
    \begin{equation}
        \boxed{
            \mathcal{M} = 
            \begin{bmatrix}
                m_{00} & \cdots & m_{0j} & \cdots & m_{0n}\\
                \vdots & \ddots & \vdots & \ddots & \vdots\\
                m_{i0} & \cdots & m_{ij} & \cdots & m_{in}\\ 
                \vdots & \ddots & \vdots & \ddots & \vdots\\
                m_{n0} & \cdots & m_{nj} & \cdots & m_{nn}\\ 
            \end{bmatrix}
        }
    \end{equation}
    Où:
    \begin{enumerate}[noitemsep]
        \item $i$: chaque ligne représente des instances de la classe actuelle;
        \item $j$: chaque colonne représente des instances de la classe de prévision;
    \end{enumerate}
    Quand on considère que les données avaient $n$ caractéristiques.
    \begin{remark}
        Dans un bon résultat:
        \begin{equation*}
            m_{ij} \to 
            \begin{cases}
                0 & \forall i\neq j\\
                N\in\mathbb{N} & \forall i= j\\
            \end{cases}
        \end{equation*}
    \end{remark}
\end{definition}

\subsubsection{Méthodes Ensemblistes}
À fin de contourner la tendance d'un algorithme au surapprentissage on peut utiliserdeux Méthodes Ensemblistes pour réduire la variance d'un model:
\begin{definition}
    \textbf{Méthodes Ensemblistes} sont des méthodes agrégeant des ensembles de classifiers en échantillonnant différemment les données. On utilise:
    \begin{enumerate}[noitemsep, rightmargin = \leftmargin]
        \item \textbf{Bagging}:
        \begin{definition}
            Développement de plusieurs modèles en parallèle.
        \end{definition}
        \item \textbf{Boosting}:
        \begin{definition}
            Développement de plusieurs modèles en série.
        \end{definition}
    \end{enumerate} 
\end{definition}  

\subsubsection{Validation Croisée}
Les algorithmes auront des performances différents pour des données distinctes, alors comme les données sont divises entre apprentissage et validation ira affecter les résultats. À fin de minimiser cette variation on peut utiliser la \textbf{Validation Croisée}:
\begin{definition}
    Cross Validation is a resampling method that uses different portions of the data, named \textbf{Fold}, to test and train a model on different iterations.\\
    
    In the end a mean of the results is taken.
    \begin{phrase}
        useful to compare the performance of different algorithmes in the same data or to validate a model
    \end{phrase}
\end{definition}

\subsubsection{Compromis Biais-Variance}
Toujours quand on analyse une algorithme de Apprentissage Automatique il faut considère le \textbf{Compromis Biais-Variance}:
\begin{definition}
    Le problème de minimiser simultanément deux sources d'erreurs qui empêchent les algorithmes d'apprentissage supervisé de généraliser au-delà de leur échantillon d'apprentissage:
    \begin{enumerate}[rightmargin = \leftmargin]
        \item \textbf{biais}:
        \begin{enumerate}[noitemsep]
            \item l'erreur provenant de la quantité d'hypothèses erronées;
        \end{enumerate}
        \begin{remark}
            Un biais élevé peut entraîner un \textbf{sous-apprentissage}, algorithme qui manque de relations pertinentes entre les données en entrée et les sorties prévues.
        \end{remark}
        On peut minimiser ce problème:
        \begin{itemize}[noitemsep]
            \item train more;
            \item increase model complexity en ajoutant des features;
        \end{itemize}

        \item \textbf{variance}:
        \begin{enumerate}[noitemsep]
            \item l'erreur provenant de la sensibilité aux petites fluctuations;
        \end{enumerate}
        \begin{remark}
            Une variance élevée peut entraîner un \textbf{sur-apprentissage}, algorithme modélise le bruit aléatoire des données d'apprentissage plutôt que les sorties prévues.
        \end{remark}
        On peut minimiser ce problème:
        \begin{itemize}[noitemsep]
            \item introduce more data;
            \item use regularization;
        \end{itemize}
    \end{enumerate}    
    La décomposition biais-variance est une façon d'analyser l'espérance de l'erreur de prédiction d'un algorithme d'apprentissage d'un problème particulier comme une somme de trois termes: le biais, la variance et une quantité, appelée erreur irréductible, résultant du bruit dans le problème lui-même. 
\end{definition}

\subsubsection{Surapprentissage}
Quand on balance le Biais et la Variance il faut toujours considère le Surapprentissage, Over-Fitting:
\begin{definition}
    Quand le modèle proposé est très spécialise, apprend pas coeur les données de traînement, et portant est mauvais pour la généralisation des données de validation.
\end{definition}
C'est indésirable et donc il faut toujours l'éviter. À ce propos on peut:
\begin{enumerate}[noitemsep, rightmargin = \leftmargin]
    \item \textbf{Data Augmentation}:
    \begin{definition}
        Ajouter des données pour l'apprentissage.
    \end{definition}
    \item \textbf{Reduced Complexity}:
    \begin{definition}
        Réduire le nombre de caractéristiques considères pour l'apprentissage.
    \end{definition}
    On peut le faire en:
    \begin{enumerate}[noitemsep]
        \item early stopping;
    \end{enumerate}
\end{enumerate}
\end{document}