\documentclass{article}
\usepackage{../../tpack/document/tpack}


\title{MA201 - Estimation Identification Statistique}
\project{Résumé Théorique}
\author{Guilherme Nunes Trofino}
\authorRA{217276}


\makeatletter
\begin{document}\selectlanguage{french}
\maketitle

\newpage\tableofcontents

\section{Introduction}
\subfile{../../intro.tex}


\subsection{Informations Matière}
\paragraph{Présentation}Ce cours sera présenter par M. Luc Meyer qui a pour but d'étudier Statistique .


\section{Statistique}
\subsection{Variables Quantitatives}
\paragraph{Définition}

\subsubsection{Moyenne}
\paragraph{Définition}
\begin{equation}
    \boxed{
        \bar{X} = \frac{1}{n} \sum^{n}_{i=1} X_{i}
    }
\end{equation}

\subsubsection{Variance}
\paragraph{Définition}
\begin{equation}
    \boxed{
        V = \frac{1}{n} \sum^{n}_{i=1} (X_{i} - \bar{X})^{2}
    }
\end{equation}

\subsubsection{Covariance}
\paragraph{Définition}
\begin{equation}
    \boxed{
        void
    }
\end{equation}

\subsubsection{Corrélation}
\paragraph{Définition}
\begin{equation}
    \boxed{
        void
    }
\end{equation}


\subsection{Modèle Statistique}
\paragraph{Définition} \href{https://en.wikipedia.org/wiki/Statistical_model}{Statistical Model}
\begin{equation}
    \boxed{
        \mathcal{M} = (\mathcal{X}^{n}, \mathcal{A}^{n}, \mathcal{P}^{n}_{\theta}, \theta\in\Theta)
    }
\end{equation}

\subsubsection{Éspace}
\paragraph{Définition}
\begin{equation}
    \boxed{
        void
    }
\end{equation}

\subsubsection{Tribu}
\paragraph{Définition} \href{https://fr.wikipedia.org/wiki/Tribu_(math%C3%A9matiques)}{Tribu}
\begin{equation}
    \boxed{
        void
    }
\end{equation}

\subsubsection{Loi de Probabilité}
\paragraph{Définition} \href{https://fr.wikipedia.org/wiki/Loi_de_probabilit%C3%A9}{Loi de Probabilité}
\begin{equation}
    \boxed{
        void
    }
\end{equation}

\subsubsection{n-Échantillon i.i.d}
\paragraph{Définition}
\begin{equation}
    \boxed{
        void
    }
\end{equation}

\subsection{Modélisation Analyse}
\subsubsection{Biais}
\paragraph{Définition}
\begin{equation}
    \boxed{
        B_{\theta}(\bar{X}_{n}, X) = \mathbb{E}[\bar{X}_{n}] - X
    }
\end{equation}
Quand $B_{\theta}(\bar{X}_{n}, X) = 0$ on considere que $\bar{X}_{n}$ est non biaisé.

\subsubsection{Variance}
\paragraph{Définition}
\begin{equation}
    \boxed{
        var(\bar{X}_{n}) = \mathbb{E}_{\theta}[(\bar{X}_{n} - \mathbb{E}_{\theta}[\bar{X}_{n}])^{2}]
    }
\end{equation}

\subsubsection{Risque Quadratique}
\paragraph{Définition}

\subsection{Estimateur}
\paragraph{Définition}
\begin{equation}
    \boxed{
        void
    }
\end{equation}

\subsubsection{Convergence}
\paragraph{Définition}

\subsubsection{Moyenne Empirique}
\paragraph{Définition}
\begin{equation}
    \boxed{
        \bar{X}_{n} = \frac{1}{n} \sum^{n}_{i=1} X_{i}
    }
\end{equation}

\subsubsection{Variance Empirique}
\paragraph{Définition}
\begin{equation}
    \boxed{
        \bar{X}_{n} = \frac{1}{n} \sum^{n}_{i=1} (X_{i} - \bar{X})^{2}
    }
\end{equation}

\subsubsection{Méthode des Moments}
\paragraph{Définition}
\begin{equation}
    \boxed{
        void
    }
\end{equation}

\subsubsection{Loi Uniforme}
\paragraph{Définition} \href{https://fr.wikipedia.org/wiki/Loi_uniforme_continue}{Loi Uniforme Continue}
\begin{equation}
    \boxed{
        f(x) = 
        \begin{cases}
            \frac{1}{b-a},  & \text{pour } a \leq x \leq b\\
            0               & \text{sinon}    
        \end{cases}
    }
\end{equation}


\section{Estimateur Bayésienne}
\paragraph{Définition}

\subsection{Introduction}
\paragraph{Définition}Il y a des différents formes d'aborder ce sujet comme presenter:
\begin{enumerate}
    \item \textbf{Fréquentiste}: Paramètre estimé theta chapeau est une variable aléatoire dont les caractéristiques dépendent de l'estimateur: Maximum de Vraisemblance, Moments, Risque Quadratique;

    \item \textbf{Bayésienne}: Paramètre est a priori une variable aléatoire associée à une distribution pi theta où theta chapeau est une variable aléatoire dont les caractéristiques dépendent de l'estimateur et de la distribution a priori;
\end{enumerate}

\subsection{Hypothèses}
\paragraph{Définition}Paramètre recherché theta vecteur aléatoire de loi a priori pi theta étant donné z, l'échantillon de données on étudie la loi jointe....
\begin{theorem}
    Soient deux événements A et B. La probabilité conditionnelle P(A|B) est obtenue par:
    \begin{equation}
        \boxed{
            P(A|B) = \frac{P(A \cup B)}{P(B)} = \frac{P(B|A)\cdot P(A)}{P(B)}
        }
    \end{equation}
    Où P(A|B) désigne la probabilité conditionnelle de A sachant B.
\end{theorem}

\subsubsection{Loi Priori}
\paragraph{Définition}

\subsubsection{Loi Marginale}
\paragraph{Définition}

\subsubsection{Loi Posteriori}
\paragraph{Définition}


Loi Marginale P(Z) loi des observations
P(Z) = int f(Z|theta)pi theta dtheta

Loi a posteriori P(theta|Z) loi de theta conditionnellement à la collecte des observations P(theta|Z) = frac{P(Z|;0)}{P(Z)} par application du théorème de Bayes P(Z; theta) se développe en P(Z|theta)pi(theta)
\begin{equation}
    \mathbb{P}(\theta | Z) = \frac{\mathbb{P}(Z|\theta)\,\pi(\theta)}{\mathbb{P}(Z)}
\end{equation}

\subsection{Objectif}
\subsubsection{Règle de Bayes}
\paragraph{Définition}Fusionner deux sources d'information:
\begin{enumerate}
    \item 
\end{enumerate}

Compensation de la déficience des observations par de hypothèses restrictives sur les valeurs à estimer, avec une base de donnés faibles c'est possible d'obtenir une loi qui marche assez bien

% \subsubsection{}
% \paragraph{Définition}
% \begin{equation}
%     \boxed{

%     }
% \end{equation}


\section{Travail Dirigé}
\subsection{Séance 03/10/2022}
\begin{scriptsize}\mycode
    \lstinputlisting[language=MATLAB, linerange={1-5}]{TD/TD4/ma201_pc4.m}
\end{scriptsize}

\newpage
population
individuel
échantillon
n-échantillon
observation

défition d'un estimateur
estimation par intervel de confiance pas dans ce cours

consistance d'un estimateur
bias et variance
estimateurs sans biais à minimum de variance
vraisemblance

cramer-rao
aider à construir des estimateur s non biaises
covariance
risque quadratique moyennes
estimateur à RQM minimal
estimateurs empiriques
variance empirique
estimateur de moment
moment théorique
moment empirique
moment centre
extention
Etheta juste pour dénoter que l'esperance depende de la variable theta
Estimateur du maximum de vraisemblance
faire la déduction des exemples
support d'un function
explore les avantages et les limites de ce méthode

% https://fr.m.wikipedia.org/wiki/Covariance

\section{Travail Dirigé}
\subsection{05/09/2022}
\subsection{19/09/2022}
\end{document}